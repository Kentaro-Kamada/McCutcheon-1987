LEM: log-linear and event history analysis with missing data.
Developed by Jeroen Vermunt (c), Tilburg University, The Netherlands.
Version 1.0 (September 18, 1997).


*** INPUT ***

  lat 1
  man 5
  dim 3 2 3 2 3 2
  lab X G P A C U
  mod G X|G 
      P|X eq2
      A|X eq2
      C|X eq2
      U|X eq2
  dat [419 71 35 25 2 5 270 42 25 16 4 5 23 6 4 2 1 0 43 9 9 3 2 2 26 1 3 2 0 0 85 13 23 12 6 8 117 34 14 19 3 5 95 23 10 14 3 2 7 3 1 1 0 0 19 2 1 1 2 1 6 3 0 1 0 0 30 9 9 7 1 4]
  des [0 0 0 0 0 0 0 0 0
       0 0 0 0 -1 0
       0 0 -1 0 0 0 0 0 0
       0 -1 0 0 0 0]
  sta A|X [.5 .5 .5 .5 .0 1.0]
  sta C|X [.5 .5 .0 .5 .5 .5 .5 .5 .5]
  sta U|X [1.0 .0 .5 .5 .5 .5]
  see 123


*** STATISTICS ***

  Number of iterations = 165
  Converge criterion   = 0.0000009534
  Seed random values   = 123

  X-squared            = 49.0168 (0.5528)
  L-squared            = 49.8223 (0.5205)
  Cressie-Read         = 48.4981 (0.5736)
  Dissimilarity index  = 0.0472
  Degrees of freedom   = 51
  Log-likelihood       = -4858.77648
  Number of parameters = 20 (+1)
  Sample size          = 1649.0
  BIC(L-squared)       = -327.9818
  AIC(L-squared)       = -52.1777
  BIC(log-likelihood)  = 9865.7114
  AIC(log-likelihood)  = 9757.5530

WARNING: no information is provided on identification of parameters



*** FREQUENCIES ***

  G P A C U     observed  estimated  std. res.
  1 1 1 1 1     419.000    407.477      0.571
  1 1 1 1 2      71.000     64.781      0.773
  1 1 1 2 1      35.000     34.532      0.080
  1 1 1 2 2      25.000     28.506     -0.657
  1 1 1 3 1       2.000      3.266     -0.700
  1 1 1 3 2       5.000      6.275     -0.509
  1 1 2 1 1     270.000    283.001     -0.773
  1 1 2 1 2      42.000     41.293      0.110
  1 1 2 2 1      25.000     26.691     -0.327
  1 1 2 2 2      16.000     17.894     -0.448
  1 1 2 3 1       4.000      4.041     -0.020
  1 1 2 3 2       5.000      4.322      0.326
  1 2 1 1 1      23.000     27.056     -0.780
  1 2 1 1 2       6.000      4.657      0.622
  1 2 1 2 1       4.000      2.365      1.064
  1 2 1 2 2       2.000      2.049     -0.034
  1 2 1 3 1       1.000      0.235      1.579
  1 2 1 3 2       0.000      0.451     -0.672
  1 2 2 1 1      43.000     37.726      0.859
  1 2 2 1 2       9.000      9.717     -0.230
  1 2 2 2 1       9.000      9.060     -0.020
  1 2 2 2 2       3.000      3.867     -0.441
  1 2 2 3 1       2.000      3.390     -0.755
  1 2 2 3 2       2.000      1.418      0.488
  1 3 1 1 1      26.000     26.546     -0.106
  1 3 1 1 2       1.000      2.703     -1.036
  1 3 1 2 1       3.000      1.944      0.758
  1 3 1 2 2       2.000      1.190      0.743
  1 3 1 3 1       0.000      0.136     -0.369
  1 3 1 3 2       0.000      0.262     -0.512
  1 3 2 1 1      85.000     76.642      0.955
  1 3 2 1 2      13.000     22.608     -2.021
  1 3 2 2 1      23.000     23.797     -0.163
  1 3 2 2 2      12.000      8.733      1.105
  1 3 2 3 1       6.000      9.761     -1.204
  1 3 2 3 2       8.000      3.609      2.312
  2 1 1 1 1     117.000    123.160     -0.555
  2 1 1 1 2      34.000     39.191     -0.829
  2 1 1 2 1      14.000     14.391     -0.103
  2 1 1 2 2      19.000     17.245      0.423
  2 1 1 3 1       3.000      1.976      0.729
  2 1 1 3 2       5.000      3.796      0.618
  2 1 2 1 1      95.000     86.123      0.957
  2 1 2 1 2      23.000     24.130     -0.230
  2 1 2 2 1      10.000     10.879     -0.267
  2 1 2 2 2      14.000     10.500      1.080
  2 1 2 3 1       3.000      2.054      0.660
  2 1 2 3 2       2.000      2.475     -0.302
  2 2 1 1 1       7.000      8.239     -0.432
  2 2 1 1 2       3.000      2.817      0.109
  2 2 1 2 1       1.000      1.002     -0.002
  2 2 1 2 2       1.000      1.240     -0.215
  2 2 1 3 1       0.000      0.142     -0.377
  2 2 1 3 2       0.000      0.273     -0.522
  2 2 2 1 1      19.000     13.850      1.384
  2 2 2 1 2       2.000      4.619     -1.219
  2 2 2 2 1       1.000      3.847     -1.451
  2 2 2 2 2       1.000      1.858     -0.629
  2 2 2 3 1       2.000      1.472      0.435
  2 2 2 3 2       1.000      0.651      0.432
  2 3 1 1 1       6.000      7.763     -0.633
  2 3 1 1 2       3.000      1.636      1.067
  2 3 1 2 1       0.000      0.739     -0.860
  2 3 1 2 2       1.000      0.720      0.330
  2 3 1 3 1       0.000      0.082     -0.287
  2 3 1 3 2       0.000      0.158     -0.398
  2 3 2 1 1      30.000     30.331     -0.060
  2 3 2 1 2       9.000      9.934     -0.296
  2 3 2 2 1       9.000     10.099     -0.346
  2 3 2 2 2       7.000      3.852      1.604
  2 3 2 3 1       1.000      4.186     -1.557
  2 3 2 3 2       4.000      1.569      1.941



*** PSEUDO R-SQUARED MEASURES ***

* P(X|G) *
                         baseline   fitted   R-squared
  entropy                 0.9662    0.9544    0.0122
  qualitative variance    0.2873    0.2828    0.0157
  classification error    0.4242    0.4242   -0.0000
  -2/N*log-likelihood     1.9324    1.9088    0.0122/0.0231
  likelihood^(-2/N)       6.9063    6.7449    0.0234/0.0273

* P(P|X) *
                         baseline   fitted   R-squared
  entropy                 0.7031    0.5074    0.2784
  qualitative variance    0.1939    0.1297    0.3310
  classification error    0.2371    0.1543    0.3494
  -2/N*log-likelihood     1.4062    1.0147    0.2784/0.2813
  likelihood^(-2/N)       4.0804    2.7587    0.3239/0.4291

* P(A|X) *
                         baseline   fitted   R-squared
  entropy                 0.6930    0.5555    0.1983
  qualitative variance    0.2499    0.1975    0.2098
  classification error    0.4912    0.3236    0.3413
  -2/N*log-likelihood     1.3860    1.1111    0.1983/0.2156
  likelihood^(-2/N)       3.9988    3.0377    0.2403/0.3205

* P(C|X) *
                         baseline   fitted   R-squared
  entropy                 0.5545    0.4678    0.1565
  qualitative variance    0.1510    0.1330    0.1190
  classification error    0.1777    0.1777    0.0000
  -2/N*log-likelihood     1.1091    0.9356    0.1565/0.1479
  likelihood^(-2/N)       3.0316    2.5487    0.1593/0.2377

* P(U|X) *
                         baseline   fitted   R-squared
  entropy                 0.5177    0.2615    0.4949
  qualitative variance    0.1675    0.0903    0.4612
  classification error    0.2129    0.1320    0.3801
  -2/N*log-likelihood     1.0354    0.5229    0.4950/0.3388
  likelihood^(-2/N)       2.8163    1.6870    0.4010/0.6218



*** LOG-LINEAR PARAMETERS ***

* TABLE G [or P(G)] *

  effect           beta   exp(beta)
  G 
   1             0.4946      1.6398 
   2            -0.4946      0.6098 

* TABLE XG [or P(X|G)] *

  effect           beta   exp(beta)
  X 
   1             0.5903      1.8045 
   2            -0.0542      0.9473 
   3            -0.5361      0.5850 
  XG 
   1 1           0.2050      1.2275 
   1 2          -0.2050      0.8147 
   2 1          -0.1893      0.8275 
   2 2           0.1893      1.2084 
   3 1          -0.0157      0.9845 
   3 2           0.0157      1.0158 



*** (CONDITIONAL) PROBABILITIES ***

* P(G) *

  1              0.7289
  2              0.2711

* P(X|G) *

  1 | 1          0.6196
  1 | 2          0.4581
  2 | 1          0.2193
  2 | 2          0.3567
  3 | 1          0.1611
  3 | 2          0.1852

* P(P|X) *

  1 | 1          0.8825
  2 | 1          0.0582
  3 | 1          0.0594
  1 | 2          0.8980
  2 | 2          0.0646
  3 | 2          0.0375
  1 | 3          0.1453
  2 | 3          0.2151
  3 | 3          0.6395

* P(A|X) *

  1 | 1          0.5986
  2 | 1          0.4014
  1 | 2          0.6396
  2 | 2          0.3604
  1 | 3          0.0000 *
  2 | 3          1.0000 *

* P(C|X) *

  1 | 1          0.9499
  2 | 1          0.0501
  3 | 1          0.0000 *
  1 | 2          0.6507
  2 | 2          0.2863
  3 | 2          0.0630
  1 | 3          0.6466
  2 | 3          0.2473
  3 | 3          0.1061

* P(U|X) *

  1 | 1          1.0000 *
  2 | 1          0.0000 *
  1 | 2          0.3423
  2 | 2          0.6577
  1 | 3          0.7367
  2 | 3          0.2633



*** LATENT CLASS OUTPUT ***

          X  1    X  2    X  3
         0.5758  0.2565  0.1676
  G  1   0.7844  0.6231  0.7005
  G  2   0.2156  0.3769  0.2995
  P  1   0.8825  0.8980  0.1453
  P  2   0.0582  0.0646  0.2151
  P  3   0.0594  0.0375  0.6395
  A  1   0.5986  0.6396  0.0000
  A  2   0.4014  0.3604  1.0000
  C  1   0.9499  0.6507  0.6466
  C  2   0.0501  0.2863  0.2473
  C  3   0.0000  0.0630  0.1061
  U  1   1.0000  0.3423  0.7367
  U  2   0.0000  0.6577  0.2633

E = 0.1368, lambda = 0.6775
