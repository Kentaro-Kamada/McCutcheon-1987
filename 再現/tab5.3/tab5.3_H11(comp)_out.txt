LEM: log-linear and event history analysis with missing data.
Developed by Jeroen Vermunt (c), Tilburg University, The Netherlands.
Version 1.0 (September 18, 1997).


*** INPUT ***

  lat 1
  man 5
  dim 3 2 3 2 3 2
  lab X G P A C U
  mod X G
      P|X eq2
      A|X eq2
      C|X eq2
      U|X eq2
  dat [419 71 35 25 2 5 270 42 25 16 4 5 23 6 4 2 1 0 43 9 9 3 2 2 26 1 3 2 0 0 85 13 23 12 6 8 117 34 14 19 3 5 95 23 10 14 3 2 7 3 1 1 0 0 19 2 1 1 2 1 6 3 0 1 0 0 30 9 9 7 1 4]
  des [2 3 0 2 3 0 0 0 0
       1 0 1 0 -1 0
       0 0 -1 0 0 0 0 0 0
       0 -1 0 0 0 0]
  sta A|X [.5 .5 .5 .5 .0 1.0]
  sta C|X [.5 .5 .0 .5 .5 .5 .5 .5 .5]
  sta U|X [1.0 .0 .5 .5 .5 .5]
  see 123


*** STATISTICS ***

  Number of iterations = 186
  Converge criterion   = 0.0000009771
  Seed random values   = 123

  X-squared            = 74.9268 (0.0464)
  L-squared            = 74.7914 (0.0475)
  Cressie-Read         = 73.9284 (0.0545)
  Dissimilarity index  = 0.0644
  Degrees of freedom   = 56
  Log-likelihood       = -4871.26102
  Number of parameters = 15 (+1)
  Sample size          = 1649.0
  BIC(L-squared)       = -340.0523
  AIC(L-squared)       = -37.2086
  BIC(log-likelihood)  = 9853.6409
  AIC(log-likelihood)  = 9772.5220

WARNING: no information is provided on identification of parameters



*** FREQUENCIES ***

  G P A C U     observed  estimated  std. res.
  1 1 1 1 1     419.000    391.315      1.400
  1 1 1 1 2      71.000     72.408     -0.165
  1 1 1 2 1      35.000     35.664     -0.111
  1 1 1 2 2      25.000     32.245     -1.276
  1 1 1 3 1       2.000      4.338     -1.123
  1 1 1 3 2       5.000      6.988     -0.752
  1 1 2 1 1     270.000    265.561      0.272
  1 1 2 1 2      42.000     50.407     -1.184
  1 1 2 2 1      25.000     26.577     -0.306
  1 1 2 2 2      16.000     22.248     -1.325
  1 1 2 3 1       4.000      4.193     -0.094
  1 1 2 3 2       5.000      5.045     -0.020
  1 2 1 1 1      23.000     26.621     -0.702
  1 2 1 1 2       6.000      4.926      0.484
  1 2 1 2 1       4.000      2.426      1.010
  1 2 1 2 2       2.000      2.194     -0.131
  1 2 1 3 1       1.000      0.295      1.297
  1 2 1 3 2       0.000      0.475     -0.689
  1 2 2 1 1      43.000     38.116      0.791
  1 2 2 1 2       9.000     10.176     -0.369
  1 2 2 2 1       9.000      9.316     -0.104
  1 2 2 2 2       3.000      4.040     -0.517
  1 2 2 3 1       2.000      3.498     -0.801
  1 2 2 3 2       2.000      1.424      0.483
  1 3 1 1 1      26.000     22.827      0.664
  1 3 1 1 2       1.000      4.224     -1.569
  1 3 1 2 1       3.000      2.080      0.638
  1 3 1 2 2       2.000      1.881      0.087
  1 3 1 3 1       0.000      0.253     -0.503
  1 3 1 3 2       0.000      0.408     -0.638
  1 3 2 1 1      85.000     77.901      0.804
  1 3 2 1 2      13.000     23.942     -2.236
  1 3 2 2 1      23.000     24.921     -0.385
  1 3 2 2 2      12.000      9.162      0.937
  1 3 2 3 1       6.000     10.244     -1.326
  1 3 2 3 2       8.000      3.659      2.269
  2 1 1 1 1     117.000    145.522     -2.364
  2 1 1 1 2      34.000     26.927      1.363
  2 1 1 2 1      14.000     13.263      0.202
  2 1 1 2 2      19.000     11.991      2.024
  2 1 1 3 1       3.000      1.613      1.092
  2 1 1 3 2       5.000      2.599      1.490
  2 1 2 1 1      95.000     98.757     -0.378
  2 1 2 1 2      23.000     18.746      0.983
  2 1 2 2 1      10.000      9.883      0.037
  2 1 2 2 2      14.000      8.274      1.991
  2 1 2 3 1       3.000      1.559      1.154
  2 1 2 3 2       2.000      1.876      0.091
  2 2 1 1 1       7.000      9.900     -0.922
  2 2 1 1 2       3.000      1.832      0.863
  2 2 1 2 1       1.000      0.902      0.103
  2 2 1 2 2       1.000      0.816      0.204
  2 2 1 3 1       0.000      0.110     -0.331
  2 2 1 3 2       0.000      0.177     -0.420
  2 2 2 1 1      19.000     14.175      1.282
  2 2 2 1 2       2.000      3.784     -0.917
  2 2 2 2 1       1.000      3.465     -1.324
  2 2 2 2 2       1.000      1.502     -0.410
  2 2 2 3 1       2.000      1.301      0.613
  2 2 2 3 2       1.000      0.530      0.646
  2 3 1 1 1       6.000      8.489     -0.854
  2 3 1 1 2       3.000      1.571      1.140
  2 3 1 2 1       0.000      0.774     -0.880
  2 3 1 2 2       1.000      0.700      0.359
  2 3 1 3 1       0.000      0.094     -0.307
  2 3 1 3 2       0.000      0.152     -0.389
  2 3 2 1 1      30.000     28.970      0.191
  2 3 2 1 2       9.000      8.904      0.032
  2 3 2 2 1       9.000      9.268     -0.088
  2 3 2 2 2       7.000      3.407      1.946
  2 3 2 3 1       1.000      3.809     -1.439
  2 3 2 3 2       4.000      1.361      2.263



*** PSEUDO R-SQUARED MEASURES ***

* P(G) *
                         baseline   fitted   R-squared
  entropy                 0.5843    0.5843    0.0000
  qualitative variance    0.1976    0.1976    0.0000
  classification error    0.2711    0.2711    0.0000
  -2/N*log-likelihood     1.1686    1.1686    0.0000/0.0000
  likelihood^(-2/N)       3.2176    3.2176    0.0000/0.0000

* P(P|X) *
                         baseline   fitted   R-squared
  entropy                 0.7031    0.4888    0.3048
  qualitative variance    0.1939    0.1237    0.3620
  classification error    0.2371    0.1441    0.3924
  -2/N*log-likelihood     1.4062    0.9776    0.3048/0.3000
  likelihood^(-2/N)       4.0804    2.6582    0.3485/0.4617

* P(A|X) *
                         baseline   fitted   R-squared
  entropy                 0.6930    0.5663    0.1828
  qualitative variance    0.2499    0.2018    0.1926
  classification error    0.4912    0.3344    0.3192
  -2/N*log-likelihood     1.3860    1.1326    0.1828/0.2022
  likelihood^(-2/N)       3.9988    3.1036    0.2239/0.2985

* P(C|X) *
                         baseline   fitted   R-squared
  entropy                 0.5545    0.4633    0.1646
  qualitative variance    0.1510    0.1320    0.1260
  classification error    0.1777    0.1777    0.0000
  -2/N*log-likelihood     1.1091    0.9265    0.1646/0.1544
  likelihood^(-2/N)       3.0316    2.5258    0.1668/0.2490

* P(U|X) *
                         baseline   fitted   R-squared
  entropy                 0.5177    0.2755    0.4679
  qualitative variance    0.1675    0.0959    0.4274
  classification error    0.2129    0.1471    0.3089
  -2/N*log-likelihood     1.0354    0.5510    0.4679/0.3263
  likelihood^(-2/N)       2.8163    1.7350    0.3840/0.5954



*** LOG-LINEAR PARAMETERS ***

* TABLE X [or P(X)] *

  effect           beta   exp(beta)
  X 
   1             0.6567      1.9285 
   2            -0.0367      0.9639 
   3            -0.6200      0.5379 

* TABLE G [or P(G)] *

  effect           beta   exp(beta)
  G 
   1             0.4946      1.6398 
   2            -0.4946      0.6098 



*** (CONDITIONAL) PROBABILITIES ***

* P(X) *

  1              0.5622
  2              0.2810
  3              0.1568

* P(G) *

  1              0.7289
  2              0.2711

* P(P|X) *

  1 | 1          0.8878
  2 | 1          0.0604
  3 | 1          0.0518
  1 | 2          0.8878
  2 | 2          0.0604
  3 | 2          0.0518
  1 | 3          0.0912
  2 | 3          0.2244
  3 | 3          0.6845

* P(A|X) *

  1 | 1          0.6034
  2 | 1          0.3966
  1 | 2          0.6034
  2 | 2          0.3966
  1 | 3          0.0000 *
  2 | 3          1.0000 *

* P(C|X) *

  1 | 1          0.9568
  2 | 1          0.0432
  3 | 1          0.0000 *
  1 | 2          0.6486
  2 | 2          0.2888
  3 | 2          0.0626
  1 | 3          0.6516
  2 | 3          0.2440
  3 | 3          0.1044

* P(U|X) *

  1 | 1          1.0000 *
  2 | 1          0.0000 *
  1 | 2          0.3830
  2 | 2          0.6170
  1 | 3          0.7482
  2 | 3          0.2518



*** LATENT CLASS OUTPUT ***

          X  1    X  2    X  3
         0.5622  0.2810  0.1568
  G  1   0.7289  0.7289  0.7289
  G  2   0.2711  0.2711  0.2711
  P  1   0.8878  0.8878  0.0912
  P  2   0.0604  0.0604  0.2244
  P  3   0.0518  0.0518  0.6845
  A  1   0.6034  0.6034  0.0000
  A  2   0.3966  0.3966  1.0000
  C  1   0.9568  0.6486  0.6516
  C  2   0.0432  0.2888  0.2440
  C  3   0.0000  0.0626  0.1044
  U  1   1.0000  0.3830  0.7482
  U  2   0.0000  0.6170  0.2518

E = 0.1417, lambda = 0.6763
