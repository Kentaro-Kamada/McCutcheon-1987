LEM: log-linear and event history analysis with missing data.
Developed by Jeroen Vermunt (c), Tilburg University, The Netherlands.
Version 1.0 (September 18, 1997).


*** INPUT ***

  lat 1
  man 5
  dim 3 2 3 2 3 2
  lab X G P A C U
  mod G 
      X|G
      P|XG eq2
      A|XG eq2
      C|XG eq2
      U|XG eq2
  dat [419 71 35 25 2 5 270 42 25 16 4 5 23 6 4 2 1 0 43 9 9 3 2 2 26 1 3 2 0 0 85 13 23 12 6 8 117 34 14 19 3 5 95 23 10 14 3 2 7 3 1 1 0 0 19 2 1 1 2 1 6 3 0 1 0 0 30 9 9 7 1 4]
  des [1 0 0 1 0 0 2 0 0 2 0 0 3 0 0 3 0 0
       0 0 0 0 0 0 0 0 -1 0 -1 0
       0 0 -1 0 0 -1 0 0 0 0 0 0 4 5 0 4 5 0
       0 -1 0 -1 0 0 0 0 0 0 0 0]
  sta A|XG [.5 .5 .5 .5 .5 .5 .5 .5 .0 1.0 .0 1.0]
  sta C|XG [.5 .5 .0 .5 .5 .0 .5 .5 .5 .5 .5 .5 .5 .5 .5 .5 .5 .5]
  sta U|XG [1.0 .0 1.0 .0 .5 .5 .5 .5 .5 .5 .5 .5]
  see 123


*** STATISTICS ***

  Number of iterations = 525
  Converge criterion   = 0.0000009979
  Seed random values   = 123

  X-squared            = 40.4424 (0.4952)
  L-squared            = 40.1704 (0.5073)
  Cressie-Read         = 39.6305 (0.5315)
  Dissimilarity index  = 0.0339
  Degrees of freedom   = 41
  Log-likelihood       = -4853.95049
  Number of parameters = 30 (+1)
  Sample size          = 1649.0
  BIC(L-squared)       = -263.5545
  AIC(L-squared)       = -41.8296
  BIC(log-likelihood)  = 9930.1387
  AIC(log-likelihood)  = 9767.9010

WARNING: no information is provided on identification of parameters



*** FREQUENCIES ***

  G P A C U     observed  estimated  std. res.
  1 1 1 1 1     419.000    413.320      0.279
  1 1 1 1 2      71.000     69.403      0.192
  1 1 1 2 1      35.000     35.881     -0.147
  1 1 1 2 2      25.000     26.069     -0.209
  1 1 1 3 1       2.000      2.772     -0.464
  1 1 1 3 2       5.000      5.600     -0.254
  1 1 2 1 1     270.000    273.010     -0.182
  1 1 2 1 2      42.000     42.157     -0.024
  1 1 2 2 1      25.000     26.663     -0.322
  1 1 2 2 2      16.000     15.906      0.024
  1 1 2 3 1       4.000      3.635      0.191
  1 1 2 3 2       5.000      3.766      0.636
  1 2 1 1 1      23.000     26.867     -0.746
  1 2 1 1 2       6.000      5.793      0.086
  1 2 1 2 1       4.000      2.532      0.922
  1 2 1 2 2       2.000      2.176     -0.119
  1 2 1 3 1       1.000      0.231      1.598
  1 2 1 3 2       0.000      0.467     -0.684
  1 2 2 1 1      43.000     37.632      0.875
  1 2 2 1 2       9.000     10.039     -0.328
  1 2 2 2 1       9.000      9.666     -0.214
  1 2 2 2 2       3.000      3.887     -0.450
  1 2 2 3 1       2.000      3.611     -0.848
  1 2 2 3 2       2.000      1.409      0.498
  1 3 1 1 1      26.000     28.906     -0.540
  1 3 1 1 2       1.000      1.954     -0.682
  1 3 1 2 1       3.000      2.057      0.657
  1 3 1 2 2       2.000      0.734      1.478
  1 3 1 3 1       0.000      0.078     -0.279
  1 3 1 3 2       0.000      0.158     -0.397
  1 3 2 1 1      85.000     78.248      0.763
  1 3 2 1 2      13.000     20.889     -1.726
  1 3 2 2 1      23.000     24.792     -0.360
  1 3 2 2 2      12.000      8.181      1.335
  1 3 2 3 1       6.000     10.097     -1.289
  1 3 2 3 2       8.000      3.412      2.483
  2 1 1 1 1     117.000    114.700      0.215
  2 1 1 1 2      34.000     35.243     -0.209
  2 1 1 2 1      14.000     13.525      0.129
  2 1 1 2 2      19.000     19.890     -0.200
  2 1 1 3 1       3.000      2.864      0.080
  2 1 1 3 2       5.000      4.213      0.383
  2 1 2 1 1      95.000     98.567     -0.359
  2 1 2 1 2      23.000     23.022     -0.005
  2 1 2 2 1      10.000      9.835      0.053
  2 1 2 2 2      14.000     12.638      0.383
  2 1 2 3 1       3.000      2.469      0.338
  2 1 2 3 2       2.000      2.852     -0.504
  2 2 1 1 1       7.000      9.209     -0.728
  2 2 1 1 2       3.000      1.924      0.776
  2 2 1 2 1       1.000      0.738      0.305
  2 2 1 2 2       1.000      1.086     -0.082
  2 2 1 3 1       0.000      0.156     -0.395
  2 2 1 3 2       0.000      0.230     -0.480
  2 2 2 1 1      19.000     13.864      1.379
  2 2 2 1 2       2.000      3.922     -0.971
  2 2 2 2 1       1.000      2.850     -1.096
  2 2 2 2 2       1.000      1.736     -0.559
  2 2 2 3 1       2.000      1.124      0.827
  2 2 2 3 2       1.000      0.603      0.511
  2 3 1 1 1       6.000      5.902      0.040
  2 3 1 1 2       3.000      2.010      0.698
  2 3 1 2 1       0.000      0.771     -0.878
  2 3 1 2 2       1.000      1.135     -0.126
  2 3 1 3 1       0.000      0.163     -0.404
  2 3 1 3 2       0.000      0.240     -0.490
  2 3 2 1 1      30.000     27.812      0.415
  2 3 2 1 2       9.000     11.606     -0.765
  2 3 2 2 1       9.000      9.492     -0.160
  2 3 2 2 2       7.000      4.761      1.026
  2 3 2 3 1       1.000      3.959     -1.487
  2 3 2 3 2       4.000      1.890      1.535



*** PSEUDO R-SQUARED MEASURES ***

* P(X|G) *
                         baseline   fitted   R-squared
  entropy                 0.9680    0.9504    0.0182
  qualitative variance    0.2883    0.2816    0.0233
  classification error    0.4286    0.4286    0.0000
  -2/N*log-likelihood     1.9360    1.9007    0.0182/0.0340
  likelihood^(-2/N)       6.9307    6.6907    0.0346/0.0405

* P(P|XG) *
                         baseline   fitted   R-squared
  entropy                 0.7031    0.5035    0.2838
  qualitative variance    0.1939    0.1288    0.3357
  classification error    0.2371    0.1522    0.3581
  -2/N*log-likelihood     1.4062    1.0070    0.2839/0.2853
  likelihood^(-2/N)       4.0804    2.7373    0.3292/0.4360

* P(A|XG) *
                         baseline   fitted   R-squared
  entropy                 0.6930    0.5578    0.1951
  qualitative variance    0.2499    0.1983    0.2067
  classification error    0.4912    0.3274    0.3335
  -2/N*log-likelihood     1.3860    1.1156    0.1951/0.2128
  likelihood^(-2/N)       3.9988    3.0514    0.2369/0.3159

* P(C|XG) *
                         baseline   fitted   R-squared
  entropy                 0.5545    0.4559    0.1778
  qualitative variance    0.1510    0.1312    0.1314
  classification error    0.1777    0.1777   -0.0000
  -2/N*log-likelihood     1.1091    0.9119    0.1778/0.1647
  likelihood^(-2/N)       3.0316    2.4890    0.1790/0.2671

* P(U|XG) *
                         baseline   fitted   R-squared
  entropy                 0.5177    0.2670    0.4843
  qualitative variance    0.1675    0.0926    0.4473
  classification error    0.2129    0.1392    0.3461
  -2/N*log-likelihood     1.0354    0.5340    0.4843/0.3340
  likelihood^(-2/N)       2.8163    1.7058    0.3943/0.6114



*** LOG-LINEAR PARAMETERS ***

* TABLE G [or P(G)] *

  effect           beta   exp(beta)
  G 
   1             0.4946      1.6398 
   2            -0.4946      0.6098 

* TABLE XG [or P(X|G)] *

  effect           beta   exp(beta)
  X 
   1             0.5722      1.7721 
   2            -0.0030      0.9970 
   3            -0.5692      0.5660 
  XG 
   1 1           0.2309      1.2597 
   1 2          -0.2309      0.7938 
   2 1          -0.2516      0.7776 
   2 2           0.2516      1.2861 
   3 1           0.0207      1.0209 
   3 2          -0.0207      0.9795 



*** (CONDITIONAL) PROBABILITIES ***

* P(G) *

  1              0.7289
  2              0.2711

* P(X|G) *

  1 | 1          0.6226
  1 | 2          0.4337
  2 | 1          0.2162
  2 | 2          0.3953
  3 | 1          0.1612
  3 | 2          0.1709

* P(P|XG) *

  1 | 1 1        0.8795
  2 | 1 1        0.0557
  3 | 1 1        0.0648
  1 | 1 2        0.8795
  2 | 1 2        0.0766
  3 | 1 2        0.0440
  1 | 2 1        0.8996
  2 | 2 1        0.0751
  3 | 2 1        0.0253
  1 | 2 2        0.8996
  2 | 2 2        0.0491
  3 | 2 2        0.0513
  1 | 3 1        0.1353
  2 | 3 1        0.2226
  3 | 3 1        0.6422
  1 | 3 2        0.1353
  2 | 3 2        0.1822
  3 | 3 2        0.6826

* P(A|XG) *

  1 | 1 1        0.6107
  2 | 1 1        0.3893
  1 | 1 2        0.5322
  2 | 1 2        0.4678
  1 | 2 1        0.6463
  2 | 2 1        0.3537
  1 | 2 2        0.6271
  2 | 2 2        0.3729
  1 | 3 1        0.0000 *
  2 | 3 1        1.0000 *
  1 | 3 2        0.0000 *
  2 | 3 2        1.0000 *

* P(C|XG) *

  1 | 1 1        0.9428
  2 | 1 1        0.0572
  3 | 1 1        0.0000 *
  1 | 1 2        0.9999
  2 | 1 2        0.0001
  3 | 1 2        0.0000 *
  1 | 2 1        0.6867
  2 | 2 1        0.2579
  3 | 2 1        0.0554
  1 | 2 2        0.5939
  2 | 2 2        0.3351
  3 | 2 2        0.0710
  1 | 3 1        0.6409
  2 | 3 1        0.2515
  3 | 3 1        0.1076
  1 | 3 2        0.6409
  2 | 3 2        0.2515
  3 | 3 2        0.1076

* P(U|XG) *

  1 | 1 1        1.0000 *
  2 | 1 1        0.0000 *
  1 | 1 2        1.0000 *
  2 | 1 2        0.0000 *
  1 | 2 1        0.3311
  2 | 2 1        0.6689
  1 | 2 2        0.4047
  2 | 2 2        0.5953
  1 | 3 1        0.7514
  2 | 3 1        0.2486
  1 | 3 2        0.6885
  2 | 3 2        0.3115



*** LATENT CLASS OUTPUT ***

          X  1    X  2    X  3
         0.5714  0.2648  0.1638
  G  1   0.7942  0.5953  0.7172
  G  2   0.2058  0.4047  0.2828
  P  1   0.8795  0.8996  0.1353
  P  2   0.0600  0.0646  0.2111
  P  3   0.0605  0.0358  0.6536
  A  1   0.5945  0.6385  0.0000
  A  2   0.4055  0.3615  1.0000
  C  1   0.9546  0.6491  0.6409
  C  2   0.0454  0.2892  0.2515
  C  3   0.0000  0.0617  0.1076
  U  1   1.0000  0.3609  0.7336
  U  2   0.0000  0.6391  0.2664

E = 0.1312, lambda = 0.6939
