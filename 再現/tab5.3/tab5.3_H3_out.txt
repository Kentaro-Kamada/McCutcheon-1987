LEM: log-linear and event history analysis with missing data.
Developed by Jeroen Vermunt (c), Tilburg University, The Netherlands.
Version 1.0 (September 18, 1997).


*** INPUT ***

  lat 1
  man 5
  dim 3 2 3 2 3 2
  lab X G P A C U
  mod G 
      X|G
      P|XG eq2
      A|XG eq2
      C|XG eq2
      U|XG eq2
  dat [419 71 35 25 2 5 270 42 25 16 4 5 23 6 4 2 1 0 43 9 9 3 2 2 26 1 3 2 0 0 85 13 23 12 6 8 117 34 14 19 3 5 95 23 10 14 3 2 7 3 1 1 0 0 19 2 1 1 2 1 6 3 0 1 0 0 30 9 9 7 1 4]
  des [1 7 0 1 7 0 2 8 0 2 8 0 3 0 0 3 0 0
       0 0 0 0 6 0 6 0 -1 0 -1 0
       0 0 -1 0 0 -1 0 0 9 0 0 9 4 5 0 4 5 0
       0 -1 0 -1 0 0 0 0 0 0 0 0]
  sta A|XG [.5 .5 .5 .5 .5 .5 .5 .5 .0 1.0 .0 1.0]
  sta C|XG [.5 .5 .0 .5 .5 .0 .5 .5 .5 .5 .5 .5 .5 .5 .5 .5 .5 .5]
  sta U|XG [1.0 .0 1.0 .0 .5 .5 .5 .5 .5 .5 .5 .5]
  see 123


*** STATISTICS ***

  Number of iterations = 215
  Converge criterion   = 0.0000009753
  Seed random values   = 123

  X-squared            = 43.3196 (0.5433)
  L-squared            = 42.8310 (0.5643)
  Cressie-Read         = 42.3744 (0.5838)
  Dissimilarity index  = 0.0349
  Degrees of freedom   = 45
  Log-likelihood       = -4855.28080
  Number of parameters = 26 (+1)
  Sample size          = 1649.0
  BIC(L-squared)       = -290.5256
  AIC(L-squared)       = -47.1690
  BIC(log-likelihood)  = 9903.1676
  AIC(log-likelihood)  = 9762.5616

WARNING: no information is provided on identification of parameters



*** FREQUENCIES ***

  G P A C U     observed  estimated  std. res.
  1 1 1 1 1     419.000    413.627      0.264
  1 1 1 1 2      71.000     68.272      0.330
  1 1 1 2 1      35.000     35.754     -0.126
  1 1 1 2 2      25.000     25.733     -0.144
  1 1 1 3 1       2.000      2.724     -0.439
  1 1 1 3 2       5.000      6.353     -0.537
  1 1 2 1 1     270.000    272.614     -0.158
  1 1 2 1 2      42.000     42.774     -0.118
  1 1 2 2 1      25.000     26.838     -0.355
  1 1 2 2 2      16.000     16.184     -0.046
  1 1 2 3 1       4.000      3.641      0.188
  1 1 2 3 2       5.000      4.283      0.347
  1 2 1 1 1      23.000     28.139     -0.969
  1 2 1 1 2       6.000      4.849      0.523
  1 2 1 2 1       4.000      2.460      0.982
  1 2 1 2 2       2.000      1.828      0.127
  1 2 1 3 1       1.000      0.193      1.833
  1 2 1 3 2       0.000      0.451     -0.672
  1 2 2 1 1      43.000     38.427      0.738
  1 2 2 1 2       9.000      9.507     -0.164
  1 2 2 2 1       9.000      9.637     -0.205
  1 2 2 2 2       3.000      3.685     -0.357
  1 2 2 3 1       2.000      3.570     -0.831
  1 2 2 3 2       2.000      1.383      0.524
  1 3 1 1 1      26.000     27.519     -0.290
  1 3 1 1 2       1.000      2.648     -1.013
  1 3 1 2 1       3.000      2.125      0.600
  1 3 1 2 2       2.000      0.998      1.003
  1 3 1 3 1       0.000      0.106     -0.325
  1 3 1 3 2       0.000      0.246     -0.496
  1 3 2 1 1      85.000     77.588      0.841
  1 3 2 1 2      13.000     21.130     -1.769
  1 3 2 2 1      23.000     24.930     -0.387
  1 3 2 2 2      12.000      8.261      1.301
  1 3 2 3 1       6.000     10.108     -1.292
  1 3 2 3 2       8.000      3.414      2.482
  2 1 1 1 1     117.000    114.887      0.197
  2 1 1 1 2      34.000     36.197     -0.365
  2 1 1 2 1      14.000     13.988      0.003
  2 1 1 2 2      19.000     20.027     -0.229
  2 1 1 3 1       3.000      2.654      0.212
  2 1 1 3 2       5.000      3.800      0.616
  2 1 2 1 1      95.000     98.353     -0.338
  2 1 2 1 2      23.000     22.631      0.078
  2 1 2 2 1      10.000      9.715      0.091
  2 1 2 2 2      14.000     12.178      0.522
  2 1 2 3 1       3.000      2.266      0.488
  2 1 2 3 2       2.000      2.507     -0.320
  2 2 1 1 1       7.000      7.871     -0.310
  2 2 1 1 2       3.000      2.571      0.268
  2 2 1 2 1       1.000      0.994      0.007
  2 2 1 2 2       1.000      1.422     -0.354
  2 2 1 3 1       0.000      0.189     -0.434
  2 2 1 3 2       0.000      0.270     -0.519
  2 2 2 1 1      19.000     12.997      1.665
  2 2 2 1 2       2.000      4.524     -1.187
  2 2 2 2 1       1.000      3.147     -1.210
  2 2 2 2 2       1.000      2.008     -0.711
  2 2 2 3 1       2.000      1.206      0.722
  2 2 2 3 2       1.000      0.665      0.412
  2 3 1 1 1       6.000      7.131     -0.424
  2 3 1 1 2       3.000      1.404      1.347
  2 3 1 2 1       0.000      0.542     -0.737
  2 3 1 2 2       1.000      0.777      0.253
  2 3 1 3 1       0.000      0.103     -0.321
  2 3 1 3 2       0.000      0.147     -0.384
  2 3 2 1 1      30.000     28.836      0.217
  2 3 2 1 2       9.000     11.415     -0.715
  2 3 2 2 1       9.000      9.255     -0.084
  2 3 2 2 2       7.000      4.603      1.117
  2 3 2 3 1       1.000      3.866     -1.458
  2 3 2 3 2       4.000      1.855      1.575



*** PSEUDO R-SQUARED MEASURES ***

* P(X|G) *
                         baseline   fitted   R-squared
  entropy                 0.9638    0.9438    0.0208
  qualitative variance    0.2866    0.2790    0.0264
  classification error    0.4230    0.4230   -0.0000
  -2/N*log-likelihood     1.9276    1.8876    0.0208/0.0385
  likelihood^(-2/N)       6.8733    6.6033    0.0393/0.0460

* P(P|XG) *
                         baseline   fitted   R-squared
  entropy                 0.7031    0.5042    0.2829
  qualitative variance    0.1939    0.1287    0.3364
  classification error    0.2371    0.1521    0.3586
  -2/N*log-likelihood     1.4062    1.0084    0.2829/0.2846
  likelihood^(-2/N)       4.0804    2.7413    0.3282/0.4347

* P(A|XG) *
                         baseline   fitted   R-squared
  entropy                 0.6930    0.5573    0.1958
  qualitative variance    0.2499    0.1981    0.2075
  classification error    0.4912    0.3269    0.3345
  -2/N*log-likelihood     1.3860    1.1146    0.1958/0.2135
  likelihood^(-2/N)       3.9988    3.0484    0.2377/0.3169

* P(C|XG) *
                         baseline   fitted   R-squared
  entropy                 0.5545    0.4579    0.1742
  qualitative variance    0.1510    0.1317    0.1278
  classification error    0.1777    0.1777   -0.0003
  -2/N*log-likelihood     1.1091    0.9158    0.1743/0.1620
  likelihood^(-2/N)       3.0316    2.4987    0.1758/0.2623

* P(U|XG) *
                         baseline   fitted   R-squared
  entropy                 0.5177    0.2600    0.4978
  qualitative variance    0.1675    0.0897    0.4645
  classification error    0.2129    0.1333    0.3736
  -2/N*log-likelihood     1.0354    0.5199    0.4979/0.3401
  likelihood^(-2/N)       2.8163    1.6819    0.4028/0.6246



*** LOG-LINEAR PARAMETERS ***

* TABLE G [or P(G)] *

  effect           beta   exp(beta)
  G 
   1             0.4946      1.6398 
   2            -0.4946      0.6098 

* TABLE XG [or P(X|G)] *

  effect           beta   exp(beta)
  X 
   1             0.5781      1.7827 
   2            -0.0191      0.9810 
   3            -0.5590      0.5718 
  XG 
   1 1           0.2491      1.2829 
   1 2          -0.2491      0.7795 
   2 1          -0.2674      0.7653 
   2 2           0.2674      1.3066 
   3 1           0.0183      1.0185 
   3 2          -0.0183      0.9819 



*** (CONDITIONAL) PROBABILITIES ***

* P(G) *

  1              0.7289
  2              0.2711

* P(X|G) *

  1 | 1          0.6317
  1 | 2          0.4298
  2 | 1          0.2074
  2 | 2          0.3965
  3 | 1          0.1609
  3 | 2          0.1737

* P(P|XG) *

  1 | 1 1        0.8799
  2 | 1 1        0.0597
  3 | 1 1        0.0604
  1 | 1 2        0.8799
  2 | 1 2        0.0597
  3 | 1 2        0.0604
  1 | 2 1        0.9011
  2 | 2 1        0.0640
  3 | 2 1        0.0349
  1 | 2 2        0.9011
  2 | 2 2        0.0640
  3 | 2 2        0.0349
  1 | 3 1        0.1344
  2 | 3 1        0.2217
  3 | 3 1        0.6439
  1 | 3 2        0.1344
  2 | 3 2        0.1940
  3 | 3 2        0.6716

* P(A|XG) *

  1 | 1 1        0.6122
  2 | 1 1        0.3878
  1 | 1 2        0.5300
  2 | 1 2        0.4700
  1 | 2 1        0.6384
  2 | 2 1        0.3616
  1 | 2 2        0.6384
  2 | 2 2        0.3616
  1 | 3 1        0.0000 *
  2 | 3 1        1.0000 *
  1 | 3 2        0.0000 *
  2 | 3 2        1.0000 *

* P(C|XG) *

  1 | 1 1        0.9396
  2 | 1 1        0.0604
  3 | 1 1        0.0000 *
  1 | 1 2        1.0000
  2 | 1 2        0.0000
  3 | 1 2        0.0000 *
  1 | 2 1        0.6803
  2 | 2 1        0.2564
  3 | 2 1        0.0633
  1 | 2 2        0.6030
  2 | 2 2        0.3336
  3 | 2 2        0.0633
  1 | 3 1        0.6415
  2 | 3 1        0.2515
  3 | 3 1        0.1070
  1 | 3 2        0.6415
  2 | 3 2        0.2515
  3 | 3 2        0.1070

* P(U|XG) *

  1 | 1 1        1.0000 *
  2 | 1 1        0.0000 *
  1 | 1 2        1.0000 *
  2 | 1 2        0.0000 *
  1 | 2 1        0.3001
  2 | 2 1        0.6999
  1 | 2 2        0.4112
  2 | 2 2        0.5888
  1 | 3 1        0.7542
  2 | 3 1        0.2458
  1 | 3 2        0.6825
  2 | 3 2        0.3175



*** LATENT CLASS OUTPUT ***

          X  1    X  2    X  3
         0.5770  0.2587  0.1643
  G  1   0.7981  0.5845  0.7135
  G  2   0.2019  0.4155  0.2865
  P  1   0.8799  0.9011  0.1344
  P  2   0.0597  0.0640  0.2138
  P  3   0.0604  0.0349  0.6518
  A  1   0.5956  0.6384  0.0000
  A  2   0.4044  0.3616  1.0000
  C  1   0.9518  0.6482  0.6415
  C  2   0.0482  0.2885  0.2515
  C  3   0.0000  0.0633  0.1070
  U  1   1.0000  0.3463  0.7337
  U  2   0.0000  0.6537  0.2663

E = 0.1257, lambda = 0.7028
