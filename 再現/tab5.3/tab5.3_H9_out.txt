LEM: log-linear and event history analysis with missing data.
Developed by Jeroen Vermunt (c), Tilburg University, The Netherlands.
Version 1.0 (September 18, 1997).


*** INPUT ***

  lat 1
  man 5
  dim 3 2 3 2 3 2
  lab X G P A C U
  mod G X|G 
      P|X eq2
      A|X eq2
      C|X eq2
      U|X eq2
  dat [419 71 35 25 2 5 270 42 25 16 4 5 23 6 4 2 1 0 43 9 9 3 2 2 26 1 3 2 0 0 85 13 23 12 6 8 117 34 14 19 3 5 95 23 10 14 3 2 7 3 1 1 0 0 19 2 1 1 2 1 6 3 0 1 0 0 30 9 9 7 1 4]
  des [2 3 0 2 3 0 0 0 0
       1 0 1 0 -1 0
       0 0 -1 0 0 0 0 0 0
       0 -1 0 0 0 0]
  sta A|X [.5 .5 .5 .5 .0 1.0]
  sta C|X [.5 .5 .0 .5 .5 .5 .5 .5 .5]
  sta U|X [1.0 .0 .5 .5 .5 .5]
  see 123


*** STATISTICS ***

  Number of iterations = 152
  Converge criterion   = 0.0000009575
  Seed random values   = 123

  X-squared            = 50.5849 (0.6069)
  L-squared            = 51.7339 (0.5623)
  Cressie-Read         = 50.0768 (0.6264)
  Dissimilarity index  = 0.0462
  Degrees of freedom   = 54
  Log-likelihood       = -4859.73223
  Number of parameters = 17 (+1)
  Sample size          = 1649.0
  BIC(L-squared)       = -348.2941
  AIC(L-squared)       = -56.2661
  BIC(log-likelihood)  = 9845.3992
  AIC(log-likelihood)  = 9753.4645

WARNING: no information is provided on identification of parameters



*** FREQUENCIES ***

  G P A C U     observed  estimated  std. res.
  1 1 1 1 1     419.000    412.911      0.300
  1 1 1 1 2      71.000     61.907      1.156
  1 1 1 2 1      35.000     34.780      0.037
  1 1 1 2 2      25.000     27.334     -0.446
  1 1 1 3 1       2.000      3.310     -0.720
  1 1 1 3 2       5.000      6.223     -0.490
  1 1 2 1 1     270.000    278.139     -0.488
  1 1 2 1 2      42.000     43.557     -0.236
  1 1 2 2 1      25.000     26.310     -0.255
  1 1 2 2 2      16.000     18.993     -0.687
  1 1 2 3 1       4.000      3.750      0.129
  1 1 2 3 2       5.000      4.576      0.198
  1 2 1 1 1      23.000     27.779     -0.907
  1 2 1 1 2       6.000      4.165      0.899
  1 2 1 2 1       4.000      2.340      1.085
  1 2 1 2 2       2.000      1.839      0.119
  1 2 1 3 1       1.000      0.223      1.647
  1 2 1 3 2       0.000      0.419     -0.647
  1 2 2 1 1      43.000     38.548      0.717
  1 2 2 1 2       9.000      9.562     -0.182
  1 2 2 2 1       9.000      9.119     -0.039
  1 2 2 2 2       3.000      3.735     -0.380
  1 2 2 3 1       2.000      3.407     -0.762
  1 2 2 3 2       2.000      1.363      0.546
  1 3 1 1 1      26.000     24.239      0.358
  1 3 1 1 2       1.000      3.634     -1.382
  1 3 1 2 1       3.000      2.042      0.671
  1 3 1 2 2       2.000      1.605      0.312
  1 3 1 3 1       0.000      0.194     -0.441
  1 3 1 3 2       0.000      0.365     -0.604
  1 3 2 1 1      85.000     76.890      0.925
  1 3 2 1 2      13.000     22.804     -2.053
  1 3 2 2 1      23.000     23.983     -0.201
  1 3 2 2 2      12.000      8.616      1.153
  1 3 2 3 1       6.000      9.852     -1.227
  1 3 2 3 2       8.000      3.489      2.415
  2 1 1 1 1     117.000    124.538     -0.675
  2 1 1 1 2      34.000     37.453     -0.564
  2 1 1 2 1      14.000     14.369     -0.097
  2 1 1 2 2      19.000     16.537      0.606
  2 1 1 3 1       3.000      2.003      0.705
  2 1 1 3 2       5.000      3.765      0.636
  2 1 2 1 1      95.000     85.052      1.079
  2 1 2 1 2      23.000     25.719     -0.536
  2 1 2 2 1      10.000     10.884     -0.268
  2 1 2 2 2      14.000     11.256      0.818
  2 1 2 3 1       3.000      1.968      0.736
  2 1 2 3 2       2.000      2.668     -0.409
  2 2 1 1 1       7.000      8.378     -0.476
  2 2 1 1 2       3.000      2.520      0.303
  2 2 1 2 1       1.000      0.967      0.034
  2 2 1 2 2       1.000      1.113     -0.107
  2 2 1 3 1       0.000      0.135     -0.367
  2 2 1 3 2       0.000      0.253     -0.503
  2 2 2 1 1      19.000     13.995      1.338
  2 2 2 1 2       2.000      4.496     -1.177
  2 2 2 2 1       1.000      3.797     -1.436
  2 2 2 2 2       1.000      1.782     -0.586
  2 2 2 3 1       2.000      1.448      0.459
  2 2 2 3 2       1.000      0.619      0.484
  2 3 1 1 1       6.000      7.311     -0.485
  2 3 1 1 2       3.000      2.199      0.540
  2 3 1 2 1       0.000      0.843     -0.918
  2 3 1 2 2       1.000      0.971      0.030
  2 3 1 3 1       0.000      0.118     -0.343
  2 3 1 3 2       0.000      0.221     -0.470
  2 3 2 1 1      30.000     30.251     -0.046
  2 3 2 1 2       9.000      9.954     -0.302
  2 3 2 2 1       9.000      9.997     -0.315
  2 3 2 2 2       7.000      3.789      1.649
  2 3 2 3 1       1.000      4.133     -1.541
  2 3 2 3 2       4.000      1.500      2.042



*** PSEUDO R-SQUARED MEASURES ***

* P(X|G) *
                         baseline   fitted   R-squared
  entropy                 0.9639    0.9521    0.0123
  qualitative variance    0.2869    0.2824    0.0159
  classification error    0.4252    0.4252   -0.0000
  -2/N*log-likelihood     1.9279    1.9041    0.0123/0.0232
  likelihood^(-2/N)       6.8748    6.7135    0.0235/0.0274

* P(P|X) *
                         baseline   fitted   R-squared
  entropy                 0.7031    0.4953    0.2955
  qualitative variance    0.1939    0.1257    0.3517
  classification error    0.2371    0.1475    0.3779
  -2/N*log-likelihood     1.4062    0.9906    0.2955/0.2936
  likelihood^(-2/N)       4.0804    2.6929    0.3400/0.4504

* P(A|X) *
                         baseline   fitted   R-squared
  entropy                 0.6930    0.5625    0.1883
  qualitative variance    0.2499    0.2003    0.1986
  classification error    0.4912    0.3303    0.3275
  -2/N*log-likelihood     1.3860    1.1250    0.1883/0.2070
  likelihood^(-2/N)       3.9988    3.0803    0.2297/0.3063

* P(C|X) *
                         baseline   fitted   R-squared
  entropy                 0.5545    0.4688    0.1546
  qualitative variance    0.1510    0.1333    0.1175
  classification error    0.1777    0.1777    0.0000
  -2/N*log-likelihood     1.1091    0.9377    0.1545/0.1463
  likelihood^(-2/N)       3.0316    2.5541    0.1575/0.2351

* P(U|X) *
                         baseline   fitted   R-squared
  entropy                 0.5177    0.2612    0.4954
  qualitative variance    0.1675    0.0901    0.4621
  classification error    0.2129    0.1321    0.3795
  -2/N*log-likelihood     1.0354    0.5225    0.4954/0.3390
  likelihood^(-2/N)       2.8163    1.6862    0.4013/0.6222



*** LOG-LINEAR PARAMETERS ***

* TABLE G [or P(G)] *

  effect           beta   exp(beta)
  G 
   1             0.4946      1.6398 
   2            -0.4946      0.6098 

* TABLE XG [or P(X|G)] *

  effect           beta   exp(beta)
  X 
   1             0.5947      1.8126 
   2            -0.0184      0.9818 
   3            -0.5763      0.5620 
  XG 
   1 1           0.2004      1.2219 
   1 2          -0.2004      0.8184 
   2 1          -0.1932      0.8243 
   2 2           0.1932      1.2131 
   3 1          -0.0072      0.9928 
   3 2           0.0072      1.0072 



*** (CONDITIONAL) PROBABILITIES ***

* P(G) *

  1              0.7289
  2              0.2711

* P(X|G) *

  1 | 1          0.6183
  1 | 2          0.4578
  2 | 1          0.2259
  2 | 2          0.3675
  3 | 1          0.1558
  3 | 2          0.1747

* P(P|X) *

  1 | 1          0.8881
  2 | 1          0.0597
  3 | 1          0.0521
  1 | 2          0.8881
  2 | 2          0.0597
  3 | 2          0.0521
  1 | 3          0.1097
  2 | 3          0.2236
  3 | 3          0.6666

* P(A|X) *

  1 | 1          0.6063
  2 | 1          0.3937
  1 | 2          0.6063
  2 | 2          0.3937
  1 | 3          0.0000 *
  2 | 3          1.0000 *

* P(C|X) *

  1 | 1          0.9494
  2 | 1          0.0506
  3 | 1          0.0000 *
  1 | 2          0.6485
  2 | 2          0.2863
  3 | 2          0.0652
  1 | 3          0.6538
  2 | 3          0.2422
  3 | 3          0.1040

* P(U|X) *

  1 | 1          1.0000 *
  2 | 1          0.0000 *
  1 | 2          0.3472
  2 | 2          0.6528
  1 | 3          0.7494
  2 | 3          0.2506



*** LATENT CLASS OUTPUT ***

          X  1    X  2    X  3
         0.5748  0.2643  0.1609
  G  1   0.7841  0.6231  0.7057
  G  2   0.2159  0.3769  0.2943
  P  1   0.8881  0.8881  0.1097
  P  2   0.0597  0.0597  0.2236
  P  3   0.0521  0.0521  0.6666
  A  1   0.6063  0.6063  0.0000
  A  2   0.3937  0.3937  1.0000
  C  1   0.9494  0.6485  0.6538
  C  2   0.0506  0.2863  0.2422
  C  3   0.0000  0.0652  0.1040
  U  1   1.0000  0.3472  0.7494
  U  2   0.0000  0.6528  0.2506

E = 0.1332, lambda = 0.6868
